{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b7ee36b",
   "metadata": {},
   "source": [
    "## Check templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ab97fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "915c51d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = jinja2.Environment(loader=jinja2.FileSystemLoader('prompts'))\n",
    "template = environment.get_template('movierecaps_coherence.jinja')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86569ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert coherence evaluator for video question answering systems. Your task is to evaluate the internal logical coherence of a model's response by comparing the claims it makes against each other. A coherent response should not contain claims that contradict one another or are excessively redundant.\n",
      "\n",
      "## Input Information\n",
      "*Question:* Inception is a mind-bending thriller that keeps viewers on the edge of their seats.\n",
      "*Claims Extracted from Model Response:*\n",
      "['The movie was thrilling from start to finish.']\n",
      "\n",
      "## Evaluation Task\n",
      "For EACH claim in the model response, evaluate its logical consistency by checking against:\n",
      "- All other claims in the same response.\n",
      "- The goal is to identify internal contradictions, not to check against external facts.\n",
      "\n",
      "## Scoring Rubric\n",
      "For each claim, assign ONE of these labels:\n",
      "- CONSISTENT (CO): The claim is logically consistent with all other claims in the response. It introduces new information or builds on previous claims without conflict.\n",
      "- REDUNDANT (R): The claim essentially repeats information already stated in another claim, using different wording. This is a minor coherence flaw but not a contradiction.\n",
      "- CONTRADICTORY (C): The claim directly contradicts information or logic present in one or more other claims.\n",
      "\n",
      "\n",
      "## Important Guidelines\n",
      "1. Strict Contradictions: Look for direct logical opposites.\n",
      "e.g., “Tony is happy” vs. “Tony is sad.”\n",
      "e.g., “The event happened in the morning” vs. “The event happened at 10 PM.”\n",
      "2. Specificity is Not Contradiction: A more specific claim is not a contradiction.\n",
      "e.g., “Tony is a doctor” and “Tony is a brain surgeon” are CONSISTENT.\n",
      "e.g., “Tony is wearing a suit” and “Tony is wearing a blue suit” are CONSISTENT.\n",
      "3. Redundancy: Identify claims that add no new information.\n",
      "e.g., “1. Tony ran quickly” and “2. Tony's speed was fast” -> Claim 2 is REDUNDANT.\n",
      "4. Reference Other Claims: In your justification for REDUNDANT or CONTRADICTORY labels, you must state the claim number of the other claim involved in the pair.\n",
      "e.g., Justification: “Contradicts claim #2, which states Tony was sad.”\n",
      "\n",
      "## Output Format\n",
      "Provide your evaluation in the following JSON format:\n",
      "\n",
      "{\n",
      "  \"claim_evaluations\": [\n",
      "    {\n",
      "      \"claim_number\": 1,\n",
      "      \"claim_text\": \"Full text of claim 1\",\n",
      "      \"label\": \"CONSISTENT|REDUNDANT|CONTRADICTORY\",\n",
      "      \"justification\": \"Brief explanation. If REDUNDANT or CONTRADICTORY, must state which claim number is related (e.g., 'Contradicts claim #4').\"\n",
      "    }\n",
      "  ],\n",
      "  \"coherence_score\": 0,\n",
      "  \"score_justification\": \"Brief explanation of why this score was assigned based on claim distribution\",\n",
      "  \"explanation\": \"Overall assessment of the response's internal consistency\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "## Coherence Score Calculation (0-5 Scale)\n",
      "After evaluating all individual claims, assign an overall coherence score from 0-5.\n",
      "- *Score 5 (Excellent)*: All claims are CONSISTENT. The response is perfectly logical and non-repetitive.\n",
      "- *Score 4 (Good)*: The vast majority of claims are CONSISTENT, with at most one or two REDUNDANT claims. No contradictions.\n",
      "- *Score 3 (Acceptable)*: Contains several REDUNDANT claims, making the response repetitive, but there are no CONTRADICTORY claims. The logic is sound, but poorly expressed.\n",
      "- *Score 2 (Poor)*: Contains at least one pair of CONTRADICTORY claims. The presence of any internal contradiction is a significant logical flaw.\n",
      "- *Score 1 (Very Poor)*: Contains multiple CONTRADICTORY claims. The response is logically confusing and hard to follow.\n",
      "- *Score 0 (Completely Incoherent)*: The majority of claims are CONTRADICTORY. The response is a logical mess and makes no sense.\n",
      "\n",
      "- *Calculation Guidelines*:\n",
      "  - Any contradiction (num_contradictory > 0) immediately drops the score to 2 or below.\n",
      "  - A high number of REDUNDANT claims reduces the score, but not as severely as a contradiction.\n",
      "\n",
      "## Claim Evaluation Examples\n",
      "Claim Set:\n",
      "- “Dr. Chilton is the head of the hospital.”\n",
      "- “Chilton seems to be in a position of authority.”\n",
      "- “Dr. Chilton is a junior intern at the facility.”\n",
      "- “He is in charge of the hospital's operations.”\n",
      "\n",
      "*Example 1: Consistent*\n",
      "- Claim: “1. Dr. Chilton is the head of the hospital.”\n",
      "- Label: CONSISTENT\n",
      "- Justification: “Initial claim establishing Chilton's role. No contradictions.”\n",
      "*Example 2: Redundant*\n",
      "- Claim: “2. Chilton seems to be in a position of authority.”\n",
      "- Label: REDUNDANT\n",
      "- Justification: “This is a weaker restatement of claim #1 ('head of the hospital').”\n",
      "*Example 3: Contradictory*\n",
      "- Claim: “3. Dr. Chilton is a junior intern at the facility.”\n",
      "- Label: CONTRADICTORY\n",
      "- Justification: “Directly contradicts claim #1, which states he is the 'head of the hospital'.”\n",
      "*Example 4: Redundant*\n",
      "- Claim: “4. He is in charge of the hospital's operations.”\n",
      "- Label: REDUNDANT\n",
      "- Justification: “Repeats the same semantic meaning as claim #1 ('head of the hospital').”\n",
      "\n",
      "## Coherence Score Examples\n",
      "* Example Response A (Score: 5)\n",
      "- 4 claims: 4 CONSISTENT, 0 REDUNDANT, 0 CONTRADICTORY\n",
      "- Score: 5 - Perfectly coherent and non-repetitive.\n",
      "* Example Response B (Score: 4)\n",
      "- 4 claims: 3 CONSISTENT, 1 REDUNDANT, 0 CONTRADICTORY\n",
      "- Score: 4 - Logically sound, just one minor repetition.\n",
      "* Example Response C (Score: 3)\n",
      "- 5 claims: 2 CONSISTENT, 3 REDUNDANT, 0 CONTRADICTORY\n",
      "- Score: 3 - Logically sound, but very repetitive. No contradictions.\n",
      "* Example Response D (Score: 2)\n",
      "- 4 claims: 2 CONSISTENT, 0 REDUNDANT, 2 CONTRADICTORY (one pair)\n",
      "- Score: 2 - The presence of a single contradiction makes the response logically flawed.\n",
      "* Example Response E (Score: 1)\n",
      "- 5 claims: 1 CONSISTENT, 2 REDUNDANT, 2 CONTRADICTORY (one pair)\n",
      "- Score: 1 - Logically flawed (contradiction) and also repetitive.\n",
      "* Example Response F (Score: 0)\n",
      "- 4 claims: 0 CONSISTENT, 0 REDUNDANT, 4 CONTRADICTORY (two pairs)\n",
      "- Score: 0 - Completely incoherent and self-contradictory.\n",
      "\n",
      "\n",
      "Now, please evaluate all claims in the model response according to these coherence guidelines\n"
     ]
    }
   ],
   "source": [
    "print(template.render(\n",
    "    claims=[\"The movie was thrilling from start to finish.\"],\n",
    "    question=\"Inception is a mind-bending thriller that keeps viewers on the edge of their seats.\"  \n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26b5fa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = jinja2.Environment(loader=jinja2.FileSystemLoader('prompts'))\n",
    "template = environment.get_template('movierecaps_factuality.jinja')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f5605e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert factuality evaluator for video question answering systems. Your task is to evaluate the factual accuracy of claims made in a model’s response by comparing them against ground truth atomic facts and dialogue from the same video segment.\n",
      "\n",
      "## Input Information\n",
      "*Question:* Inception is a mind-bending thriller that keeps viewers on the edge of their seats.\n",
      "*Claims Extracted from Model Response:*\n",
      "['The movie was thrilling from start to finish.']\n",
      "*Ground Truth Atomic Facts from Video Segment:*\n",
      "['Inception was released in 2010.', 'The director of Inception is Christopher Nolan.']\n",
      "*SRT Dialogue Context:*\n",
      "Inception is a science fiction film that explores the concept of dream invasion.\n",
      "\n",
      "## Evaluation Task\n",
      "For EACH claim in the model response, evaluate its factual accuracy by checking against:\n",
      "1. The ground truth atomic facts\n",
      "2. The SRT dialogue context\n",
      "\n",
      "## Scoring Rubric\n",
      "For each claim, assign ONE of these labels:\n",
      "- *SUPPORTED (S)*: The claim is directly supported by the ground truth facts or dialogue. The information matches accurately.\n",
      "- *PARTIALLY_SUPPORTED (PS)*: The claim contains some accurate information but also includes unsupported details, or is less precise than the ground truth.\n",
      "- *UNSUPPORTED (U)*: The claim makes statements that are not mentioned in the ground truth facts or dialogue. This may be a reasonable inference but lacks direct support.\n",
      "- *CONTRADICTORY (C)*: The claim directly contradicts information in the ground truth facts or dialogue.\n",
      "- *NOT_CHECKABLE (NC)*: The claim cannot be verified from the provided facts and dialogue (e.g., references information from outside the segment).\n",
      "## Important Guidelines\n",
      "1. *Penalize hallucinations strictly*:\n",
      "   - Any claim adding information not in facts/dialogue should be marked UNSUPPORTED or CONTRADICTORY\n",
      "   - Be especially careful with specific titles, roles, or relationships\n",
      "2. *Consider the dialogue*:\n",
      "   - The SRT dialogue may contain information not captured in atomic facts\n",
      "   - Check both sources before marking something as unsupported\n",
      "\n",
      "## Output Format\n",
      "Provide your evaluation in the following JSON format:\n",
      "\n",
      "{\n",
      "  \"claim_evaluations\": [\n",
      "    {\n",
      "      \"claim_number\": 1,\n",
      "      \"claim_text\": \"Full text of claim 1\",\n",
      "      \"label\": \"SUPPORTED|PARTIALLY_SUPPORTED|UNSUPPORTED|CONTRADICTORY|NOT_CHECKABLE\",\n",
      "      \"justification\": \"Brief explanation referencing specific facts or dialogue\",\n",
      "      \"supporting_facts\": [\"List of facts that support this claim from the given input\"],\n",
      "      \"supporting_dialogue\": \"Relevant dialogue excerpt if applicable\"\n",
      "    }\n",
      "  ],\n",
      "  \"factuality_score\": 0,\n",
      "  \"score_justification\": \"Brief explanation of why this score was assigned based on claim distribution\",\n",
      "  \"explanation\": \"Overall assessment of the response's factuality\"\n",
      "}\n",
      "\n",
      "\n",
      "## Factuality Score Calculation (0-5 Scale)\n",
      "After evaluating all individual claims, assign an overall factuality score from 0-5 based on the aggregate quality:\n",
      "*Score 5 (Excellent)*: All claims are SUPPORTED. No unsupported or contradictory information.\n",
      "*Score 4 (Good)*: Majority of claims are SUPPORTED, with at most minor PARTIALLY_SUPPORTED claims. No contradictions or hallucinations.\n",
      "*Score 3 (Acceptable)*: Mix of SUPPORTED and PARTIALLY_SUPPORTED claims, or some UNSUPPORTED claims present but no contradictions. The response is generally accurate but has gaps.\n",
      "*Score 2 (Poor)*: Multiple UNSUPPORTED claims or at least one CONTRADICTORY claim. Significant factual issues present.\n",
      "*Score 1 (Very Poor)*: Mostly UNSUPPORTED or multiple CONTRADICTORY claims. The response contains more incorrect than correct information.\n",
      "*Score 0 (Completely Incorrect)*: All claims are CONTRADICTORY or UNSUPPORTED. The response is factually wrong or completely fabricated.\n",
      "*Calculation Guidelines:*\n",
      "- Prioritize accuracy over completeness\n",
      "- Contradictions are more severe than unsupported claims\n",
      "- Weight recent claims equally (don’t discount later claims)\n",
      "- Consider the proportion: % supported, % partially supported, % unsupported, % contradictory\n",
      "\n",
      "## Examples\n",
      "*Example 1: Supported Claim*\n",
      "- Claim: “Dr. Chilton works at the Baltimore State Forensic Hospital”\n",
      "- Fact: “Dr. Frederick Chilton works at the Baltimore State Forensic Hospital”\n",
      "- Dialogue: Contains “Baltimore State Forensic Hospital”\n",
      "- Label: SUPPORTED\n",
      "- Justification: “Directly matches fact #1 and is mentioned in dialogue”\n",
      "*Example 2: Partially Supported*\n",
      "- Claim: “Dr. Chilton is the head psychiatrist for Lecter”\n",
      "- Facts: “Dr. Chilton explains they have tried to study Lecter”, “Lecter is their most prized asset”\n",
      "- Label: PARTIALLY_SUPPORTED\n",
      "- Justification: “While Chilton clearly has authority over Lecter’s care, the specific title ‘head psychiatrist’ is not stated in facts or dialogue”\n",
      "*Example 3: Unsupported*\n",
      "- Claim: “Dr. Chilton has been working at the facility for 10 years”\n",
      "- Facts: No mention of duration\n",
      "- Label: UNSUPPORTED\n",
      "- Justification: “No information about length of employment in facts or dialogue”\n",
      "*Example 4: Contradictory*\n",
      "- Claim: “Dr. Chilton is kind and respectful to Clarice”\n",
      "- Dialogue: Shows Chilton making suggestive remarks\n",
      "- Fact: “Dr. Chilton makes suggestive remarks at Clarice Starling”\n",
      "- Label: CONTRADICTORY\n",
      "- Justification: “Contradicts fact #2 which states he makes suggestive remarks”\n",
      "## Overall Score Examples\n",
      "*Example Response A* (Score: 5)\n",
      "- 3 claims: 3 SUPPORTED, 0 PARTIALLY_SUPPORTED, 0 UNSUPPORTED, 0 CONTRADICTORY\n",
      "- Score: 5 - All claims are directly supported by facts\n",
      "*Example Response B* (Score: 4)\n",
      "- 4 claims: 3 SUPPORTED, 1 PARTIALLY_SUPPORTED, 0 UNSUPPORTED, 0 CONTRADICTORY\n",
      "- Score: 4 - Mostly supported with one minor imprecision\n",
      "*Example Response C* (Score: 3)\n",
      "- 5 claims: 2 SUPPORTED, 2 PARTIALLY_SUPPORTED, 1 UNSUPPORTED, 0 CONTRADICTORY\n",
      "- Score: 3 - Mix of accurate and unsupported, but no contradictions\n",
      "*Example Response D* (Score: 2)\n",
      "- 4 claims: 1 SUPPORTED, 1 PARTIALLY_SUPPORTED, 1 UNSUPPORTED, 1 CONTRADICTORY\n",
      "- Score: 2 - Contains contradiction and multiple issues\n",
      "*Example Response E* (Score: 1)\n",
      "- 4 claims: 0 SUPPORTED, 1 PARTIALLY_SUPPORTED, 3 UNSUPPORTED, 0 CONTRADICTORY\n",
      "- Score: 1 - Mostly hallucinated information\n",
      "*Example Response F* (Score: 0)\n",
      "- 3 claims: 0 SUPPORTED, 0 PARTIALLY_SUPPORTED, 1 UNSUPPORTED, 2 CONTRADICTORY\n",
      "- Score: 0 - Contradicts ground truth facts\n",
      "\n",
      "\n",
      "Now, please evaluate all claims in the model response according to these guidelines.\n"
     ]
    }
   ],
   "source": [
    "print(template.render(\n",
    "    claims=[\"The movie was thrilling from start to finish.\"],\n",
    "    question=\"Inception is a mind-bending thriller that keeps viewers on the edge of their seats.\", \n",
    "    facts=[\"Inception was released in 2010.\", \"The director of Inception is Christopher Nolan.\" ],\n",
    "    context=\"Inception is a science fiction film that explores the concept of dream invasion.\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c7eb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
